---
title:  "Day 61: 딥러닝 혁명의 신호탄, AlexNet의 등장"
categories:
  - cs_history
toc: true
toc_sticky: true
comments: true
---

안녕하세요, 기술의 흐름을 추적하는 시니어 테크 히스토리언입니다. 지난 시간에는 웹 브라우저의 성능을 비약적으로 끌어올린 Google V8 엔진을 살펴보았습니다. 오늘은 그로부터 4년 뒤, 컴퓨터 과학계뿐만 아니라 인류의 미래를 바꿔놓은 거대한 사건을 다루려 합니다. 바로 인공지능의 '빅뱅'이라 불리는 AlexNet의 등장입니다.

## 🕰️ 오늘의 키워드: AlexNet
 * 원어: AlexNet (ImageNet Classification with Deep Convolutional Neural Networks)
 * 시기: 2012년 (ILSVRC 2012 우승)

2012년, 토론토 대학교의 알렉스 크리제프스키(Alex Krizhevsky), 일리야 수츠케버(Ilya Sutskever), 그리고 그들의 지도교수 제프리 힌튼(Geoffrey Hinton)은 'AlexNet'이라는 이름의 심층 합성곱 신경망(Deep Convolutional Neural Network, CNN)을 세상에 내놓았습니다. 이들은 1,000개의 카테고리로 분류된 수백만 장의 이미지를 식별하는 '이미지넷(ImageNet)' 대회에서 압도적인 성적으로 우승하며, 현대 인공지능 시대의 개막을 알렸습니다.

## ⚡ 무엇이 혁명적이었나? (Deep Dive)
AlexNet은 단순히 성능이 좋은 모델이 아니었습니다. 이전까지의 컴퓨터 비전 방식이 사람이 직접 특징을 정의하던 '수동(Handcrafted)' 방식이었다면, AlexNet은 데이터로부터 특징을 스스로 학습하는 '딥러닝'의 실용성을 증명했습니다. 그 핵심 기술적 돌파구는 다음과 같습니다.

*   **ReLU 활성화 함수(ReLU Activation Function):** 기존의 시그모이드(Sigmoid)나 탄젠트(tanh) 함수 대신 ReLU를 사용했습니다. 이는 기울기 소실(Vanishing Gradient) 문제를 완화하여 학습 속도를 수배 이상 가속화했습니다.
*   **드롭아웃(Dropout) 규제:** 신경망이 너무 복잡해지면 학습 데이터에만 과하게 최적화되는 과적합(Overfitting)이 발생합니다. AlexNet은 학습 중 무작위로 뉴런을 비활성화하는 드롭아웃 기법을 도입해 모델의 범용성을 확보했습니다.
*   **GPU 가속(GPU Acceleration):** 당시로서는 파격적으로 NVIDIA의 GTX 580 GPU 두 장을 병렬로 연결해 학습을 진행했습니다. CPU로는 수개월이 걸릴 계산을 GPU의 병렬 연산 능력을 빌려 현실적인 시간 내에 끝낸 것입니다. 이는 오늘날 'AI=GPU'라는 공식을 만든 결정적 계기가 되었습니다.
*   **중첩 최대 풀링(Overlapping Max Pooling):** 풀링 윈도우를 겹치게 설정하여 특징의 손실을 줄이고 공간적 계층 구조를 더 잘 파악하도록 설계했습니다.

당시 2위 모델의 에러율이 26.2%였던 반면, AlexNet은 15.3%라는 경이로운 수치를 기록했습니다. 이 10% 이상의 격차는 학계에 엄청난 충격을 주었고, 이후 모든 연구자가 딥러닝으로 방향을 선회하게 만들었습니다.

## 🔗 현대와의 연결: 딥러닝의 표준이 되다
AlexNet이 정립한 기술적 표준은 10년이 지난 지금도 유효합니다. 오늘날 우리가 스마트폰에서 사용하는 얼굴 인식, 자율주행 자동차의 사물 식별, 의료 영상 분석 시스템의 뿌리에는 모두 AlexNet의 CNN 구조가 자리 잡고 있습니다.

특히 흥미로운 점은 AlexNet의 공동 저자인 일리야 수츠케버가 이후 OpenAI의 공동 창립자로서 ChatGPT와 같은 거대 언어 모델(LLM) 탄생의 주역이 되었다는 사실입니다. AlexNet이 보여준 '거대한 데이터를 깊은 신경망과 강력한 컴퓨팅 파워로 학습시킨다'는 철학은 이미지 인식을 넘어 자연어 처리, 그리고 생성형 AI 시대로 이어지는 거대한 흐름의 시작점이었습니다.

## 📅 내일의 키워드 예고
AlexNet이 딥러닝의 가능성을 증명했다면, 다음 과제는 '더 깊게' 쌓는 것이었습니다. 하지만 층이 깊어질수록 학습이 되지 않는 한계에 부딪히게 되죠. 내일은 이 한계를 극복하고 수백 층의 신경망을 가능하게 한 **ResNet(2015)**에 대해 알아보겠습니다.

## 📚 참고 문헌
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHAjbrT_w50qO5TA9R6mtX0SLI34hUlDC9F-fMRAkmfXxNV_IP0Ve6jeVmpYDg5sTg19TMQibPBOueGHUBCsx549L6Gs142-ifL0udLIawdpC7lSC5MZWZF-JVQtwJ1nj1eZZd3gWbLgpuswZfrliQxscS0wC6aGjVCZSCjGaFw-HqVgR2kaIlaaTUnHhey5dm9p6AKC7r6B-ZJbWcEpJQI6vMkD8X73b1U0gagokHvjOMqQFvKwo6O2pHMbH79FJhL0fv9A4E2JJ1xmd0kIIM=)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFv7CLJq8oSZNeLzEN_Ovt7TAqS5kI4ngXGf7gsNqJlvvp3SOH6_BQcE30kVRT32BPTvRkPvK5jlobGcKdSZG-gW8PJ9umktwBZmUQJWE1g-wRsoMazAQqprh-rWqIsRhu2IAEjnJW54BEHpOA4onVB91tBqfNdsVxDOGHYXaBla1MrJPVUfqxEVvVQK22sNCzQQWn_WvM4kk_GqVoMUmT5sqq-bA==)
* [wikipedia.org](https://en.wikipedia.org/wiki/AlexNet)
* [pinecone.io](https://www.pinecone.io/learn/series/image-search/imagenet/)
* [image-net.org](https://www.image-net.org/challenges/LSVRC/2012/)
* [tensorflow.org](https://www.tensorflow.org/datasets/catalog/imagenet2012)
* [viso.ai](https://viso.ai/deep-learning/alexnet/)
* [mygreatlearning.com](https://www.mygreatlearning.com/blog/alexnet-the-first-cnn-to-win-image-net/)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEbvboq-Im_CYYE07Az9UmnywuWVPapFL6a1YX1kbx1qSyA9PHKBbifsC1fzhlSa6OF5adexfkJM3MBGXjSEh1H4Jj84800dmt3GZrx1G-x8O21NPwh2Itl1Eh6cvwoZs_R7kYSnZH6GneFjSInq5YYrqGL5WKDDJopPiXQlfAU3dnQqSzBO9aCaUB8y1EtxstUVAla)
* [gitconnected.com](https://levelup.gitconnected.com/alexnet-explained-a-step-by-step-guide-93870b45126b?gi=688ff81a6bbc)
* [learnopencv.com](https://learnopencv.com/understanding-alexnet/)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFoR8iQxivj8y5swQcqkIwE5WsJqbKoIW4hy-FuukLYIjNWVwSUevSCjgfiVw4uwat0l5z96UPyoNsI1dw92TrK7DiQvNHWlHawm4_Ef7vBGykW8T0OJn7J0LZaGDZ0alyQX38qx85Av8Wwn2yNgDPUVeyDeso0F-akRfUy-nHzbGCVwAPc_Po=)
* [staroceans.org](http://www.staroceans.org/wiki/A/AlexNet)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQECm_qWzLoUthUnpXvWC8mS3UJtxMb-lpV8o_vY1ibpJL3Vfhz-KHz7xe6D3e_Z7kpbgHQEr6oC2hJ9U9ZNmSnbLfODcE6Uw-sD7-lPgHNy4uOTyS7eiQBno2GJgQRS1vz1XG8UmaSJG2k8cGok4dLeRFwbo51Aotawe7pwQhgpmr1UcK_n6qGAxTPU53xMVCwGf319B23qQInD)
* [d2l.ai](http://d2l.ai/chapter_convolutional-modern/alexnet.html)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG0DIk1YaxocjT4glsXAoaGjhFR0iaU02c-gDeH6fBXnVWicMsa2zBfRnxtd-b3YjQmjQMT9bOJtZynReGLlter7meZHjkyPMusSH2Lg1QU0x4iIwFdyaWkySYJLfI0zEEN67QWiZr95HWAiaBA4-calUAX6EWqQelVYeMGbhtb6zJMdtY8z6kAhe71_SupKll52PAbj6y8h4qwxI2J1dQ=)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFI4DQVqULS0MT2PD5-DzTxfkVORL3HhQpgSuCrwqfLVbfBuHz-BXufM5E0lNHC_X1_Ew538YLjDzymzrk1nfdpYywSTgkqzPVr28PzJguaBsfyHCt9g5Jqri31l4MiS_7fI5dex5VoorDbcJrmlLXHVJTW74ECbfhY8OZ7tKaMok41DrGftVu6gS0DqsVkrTNOx6E3_wrStJQ2Kv_1nFD2fWxDTknA74IbKy-bQ5UXVeD8CVIn_Sc=)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEAw6ZglnTLmx0OIa4fyvJ2Qah2AmihljhNgjLuyPeSK6DaWdhSA_H70NdqaE45-pU60owWBZVO2jGlvRKgTM7FCEZ3UY0_EK7Pb2dsCerSaN_3lHRYse0zu-iFKfW2SPgHZxksIc7EtviOj8vP96aRBBYpFZTib4N6tZ93v_teAvaAVyV3COHIEufbuEIh6LpLqRBxHXJqlMhqYsdnTiE8AMH65iJCBw==)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGZdkKSMWVWkaL2gj36Jld3Cy2rSyCf5GoovyGaBuaV45n4HAnmCy5uBxdfZOtG_mj0LCWADZJQeDk4i71TNEk3g6Bz6z9cuPDTuERbI1mzZSI5touScwUIPHVlvPhMROo-pif3Z3Fyo-1BPhZWskQUOe9jr4MFw7v1ftaL-vz2-INXMfloyeZCCSpgLTHZM1mK6ptbFDquEmnPXcm_R7-y0fiBWJhoqT36_sZ4)
* [bme.hu](https://static.hlt.bme.hu/semantics/external/pages/backprop/en.wikipedia.org/wiki/AlexNet.html)
* [dev.ua](https://dev.ua/en/news/vykhidnyi-kod-iakyi-transformuvav-sferu-shtuchnoho-intelektu-u-2012-rotsi-vyklaly-u-zahalnyi-dostup-na-github-1742898596)
* [youtube.com](https://www.youtube.com/watch?v=g3encXReqpo)
* [wikipedia.org](https://en.wikipedia.org/wiki/Timeline_of_machine_learning)


*이 콘텐츠는 AI에 의해 생성되었으며, 오류나 부정확한 정보를 포함할 수 있습니다.*