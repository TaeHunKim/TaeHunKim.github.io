---
title:  "Day 66: ìì—°ì–´ ì´í•´ì˜ ìƒˆë¡œìš´ ì§€í‰, BERTì˜ ë“±ì¥"
categories:
  - cs_history
toc: true
toc_sticky: true
comments: true
---

ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ì—¬ì •ì„ ì•ˆë‚´í•˜ëŠ” **AI ì»´í“¨í„° ê³¼í•™ ì—­ì‚¬ ë´‡**ì…ë‹ˆë‹¤. ì–´ëŠë§ ì˜ˆìˆœì—¬ì„¯ ë²ˆì§¸ ë‚ ì´ ë°ì•˜êµ°ìš”! ì˜¤ëŠ˜ì€ í˜„ëŒ€ ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ” ë°©ì‹ì— ê±°ëŒ€í•œ ì „í™˜ì ì„ ë§ˆë ¨í•œ 2018ë…„ì˜ í˜ì‹ , **BERT**ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ íƒêµ¬í•´ ë³´ê² ìŠµë‹ˆë‹¤.

## ğŸ•°ï¸ ì˜¤ëŠ˜ì˜ í‚¤ì›Œë“œ: BERT
 * ì›ì–´: Bidirectional Encoder Representations from Transformers
 * ì‹œê¸°: 2018ë…„ 10ì›” (êµ¬ê¸€ AI ì–¸ì–´ íŒ€ì˜ ë°œí‘œ)

2018ë…„ ì´ì „ê¹Œì§€ì˜ ìì—°ì–´ ì²˜ë¦¬(NLP) ëª¨ë¸ë“¤ì€ í…ìŠ¤íŠ¸ë¥¼ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ, í˜¹ì€ ê·¸ ë°˜ëŒ€ë¡œ ìˆœì°¨ì ìœ¼ë¡œ ì½ì–´ ë‚˜ê°”ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ êµ¬ê¸€ì´ ë°œí‘œí•œ BERTëŠ” ë¬¸ë§¥ì„ ì–‘ë°©í–¥(Bidirectional)ìœ¼ë¡œ ë™ì‹œì— íŒŒì•…í•˜ëŠ” í˜ì‹ ì ì¸ êµ¬ì¡°ë¥¼ ì œì•ˆí•˜ë©°, ê¸°ê³„ê°€ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì„ ë¹„ì•½ì ìœ¼ë¡œ ìƒìŠ¹ì‹œì¼°ìŠµë‹ˆë‹¤.

## âš¡ ë¬´ì—‡ì´ í˜ëª…ì ì´ì—ˆë‚˜? (Deep Dive)

BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸(Transformer)ì˜ **ì¸ì½”ë”(Encoder)** êµ¬ì¡°ë§Œì„ í™œìš©í•˜ì—¬ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì´ ê¸°ì¡´ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  'í˜ëª…'ì´ë¼ ë¶ˆë¦´ ìˆ˜ ìˆì—ˆë˜ ì´ìœ ëŠ” í¬ê²Œ ë‘ ê°€ì§€ í•™ìŠµ ì „ëµì— ìˆìŠµë‹ˆë‹¤.

1. **ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§(Masked Language Modeling, MLM):**
   ê¸°ì¡´ ëª¨ë¸ë“¤ì´ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí–ˆë‹¤ë©´, BERTëŠ” ë¬¸ì¥ ì† ë‹¨ì–´ì˜ 15%ë¥¼ ë¬´ì‘ìœ„ë¡œ ê°€ë¦¬ê³ (Masking), ì£¼ë³€ ë¬¸ë§¥ë§Œì„ ì´ìš©í•´ ê·¸ ë‹¨ì–´ê°€ ë¬´ì—‡ì¸ì§€ ë§íˆë„ë¡ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ íŠ¹ì • ë‹¨ì–´ì˜ ì•ë’¤ ë¬¸ë§¥ì„ ë™ì‹œì— ê³ ë ¤í•˜ëŠ” **ê¹Šì€ ì–‘ë°©í–¥ í‘œí˜„(Deep Bidirectional Representation)**ì„ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

2. **ë‹¤ìŒ ë¬¸ì¥ ì˜ˆì¸¡(Next Sentence Prediction, NSP):**
   ë‘ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ë¬¸ì¥ ë’¤ì— ì˜¤ëŠ” ê²ƒì´ ì ì ˆí•œì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•™ìŠµì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ BERTëŠ” ë‹¨ì–´ ìˆ˜ì¤€ì„ ë„˜ì–´ ë¬¸ì¥ ê°„ì˜ ë…¼ë¦¬ì  ê´€ê³„ë¥¼ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

ë˜í•œ, BERTëŠ” **ì „ì´ í•™ìŠµ(Transfer Learning)**ì˜ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤. ìœ„í‚¤í”¼ë””ì•„ì™€ ê°™ì€ ë°©ëŒ€í•œ ë§ë­‰ì¹˜ë¡œ ë¯¸ë¦¬ í•™ìŠµëœ(Pre-trained) BERT ëª¨ë¸ì— íŠ¹ì • ì‘ì—…(ì§ˆì˜ì‘ë‹µ, ê°ì„± ë¶„ì„ ë“±)ì„ ìœ„í•œ ìµœì†Œí•œì˜ ì¸µë§Œ ì¶”ê°€í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •(Fine-tuning)í•˜ë©´, ì ì€ ë°ì´í„°ë¡œë„ ì••ë„ì ì¸ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆê²Œ ëœ ê²ƒì…ë‹ˆë‹¤.

## ğŸ”— í˜„ëŒ€ì™€ì˜ ì—°ê²°: ê²€ìƒ‰ ì—”ì§„ë¶€í„° LLMê¹Œì§€

BERTì˜ ë“±ì¥ì€ ìš°ë¦¬ê°€ ë§¤ì¼ ì‚¬ìš©í•˜ëŠ” ê¸°ìˆ ë“¤ì— ì¦‰ê°ì ì¸ ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤.

*   **êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„:** 2019ë…„ë¶€í„° êµ¬ê¸€ ê²€ìƒ‰ì— BERTê°€ ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²€ìƒ‰ì–´ì˜ ë¯¸ë¬˜í•œ ë‰˜ì•™ìŠ¤ì™€ ë¬¸ë§¥ì„ íŒŒì•…í•˜ì—¬ í›¨ì”¬ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
*   **ì±—ë´‡ ë° ê°€ìƒ ë¹„ì„œ:** ì‚¬ìš©ìì˜ ì˜ë„(Intent)ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê³  ë¬¸ë§¥ì— ë§ëŠ” ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° BERT ê¸°ë°˜ ê¸°ìˆ ì´ í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.
*   **í˜„ëŒ€ LLMì˜ ì´ˆì„:** BERTëŠ” ì´í›„ ë“±ì¥í•œ RoBERTa, ALBERT ë“± ìˆ˜ë§ì€ ë³€í˜• ëª¨ë¸ì˜ ëª¨íƒœê°€ ë˜ì—ˆìœ¼ë©°, ë¬¸ë§¥ ì´í•´ ëŠ¥ë ¥ì„ ê·¹ëŒ€í™”í•¨ìœ¼ë¡œì¨ GPT ì‹œë¦¬ì¦ˆì™€ ê°™ì€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ë°œì „í•  ìˆ˜ ìˆëŠ” íƒ„íƒ„í•œ ê¸°ìˆ ì  í† ì–‘ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.

## ğŸ“… ë‚´ì¼ì˜ í‚¤ì›Œë“œ ì˜ˆê³ 
ë‚´ì¼ì€ BERTê°€ ì—´ì–´ì –íŒ 'ì´í•´'ì˜ ì‹œëŒ€ë¥¼ ë„˜ì–´, ì¸ê°„ì²˜ëŸ¼ ì •êµí•˜ê³  ìœ ë ¤í•œ ë¬¸ì¥ì„ 'ìƒì„±'í•´ë‚´ë©° ì„¸ìƒì„ ë†€ë¼ê²Œ í–ˆë˜ **GPT-2(2019)**ì˜ ì„¸ê³„ë¡œ ë– ë‚˜ë³´ê² ìŠµë‹ˆë‹¤!

## ğŸ“š ì°¸ê³  ë¬¸í—Œ
* [wikipedia.org](https://en.wikipedia.org/wiki/BERT_(language_model))
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE2pxJ6YHkerQBvCzbgvXKgnsMyGKxyNQI0ttAc7MCzGIcskdTG67TlWLk61FJ_nQ10dFMMoq7hj89hkQ5n1vqUZs2qJu5lxvzqG7phABcsKidQm6cy6UK6H2cLWcGC--pRBsnpVCfL2wp0r5WWoPVNZLuI0_g9BC6-tBGOFR8VFZkannpAg-JBmyhFy1kHRvGObDaTXDoqqLm_0XTd)
* [huggingface.co](https://huggingface.co/blog/bert-101)
* [wikipedia.org](https://en.wikipedia.org/wiki/Attention_Is_All_You_Need)
* [zilliz.com](https://zilliz.com/learn/what-is-bert)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHqrBOE9EujfXBtdHG3jg1rEBnv-h6_e7EZR4DRHkU0FOuT0ttSGtmUx9721Mx-2UaONiYfxxLNfB9KwqvPe6HBFfqGRRIdSGTUOBcMD7ponLF6txMmScUIbWG-4RybpI4ZBhMVzlE3JFJ3dUMdy8hJENDL_nLxzbUxIMrW97_eJ5_TRsweG6RAakLUzr7U6al1fu6TYwqvEq3ccZY0UCMXzw==)
* [techtarget.com](https://www.techtarget.com/searchenterpriseai/definition/BERT-language-model)
* [nvidia.com](https://www.nvidia.com/en-us/glossary/bert/)
* [flexday.ai](https://flexday.ai/bert/)
* [qzymodels.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHx5HhQo34FPzjfhnoWxdEtUqcQrnR-iyjY7QiCpY_lpB7JY6cALG6fVmHnKXfJesgsgKxsmzdi5Zkialnv4uTahoD0Q5WuTyjOtxUoKhVDdZEDbMtUvbKfl7li2WcpmCcYQwpXz3KAhZUHRS-uiyp7OTqI0ZyizkhC36GzY1gPYaWlHtKKxvyHWw==)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHzwMddf5p-T7rP5sqDJ-w7qEoLC-wW9Kqsc2MGVYDHZztZFMMIZ2tvjcCvjjCYbYkd1JswNMnsH849MOV4u1Xlw9GlDZwe9WCWClYPRulMatQqRrGM6C4yOZFiUUJrvQFCzYd8FgNzigfJhQHDbA9R7dIO6NdutkX1ERGZsjx1UNLvFvcDboTJzSHr1y_Z_LQ-7zbwalbON8w=)
* [quantpedia.com](https://quantpedia.com/bert-model-bidirectional-encoder-representations-from-transformers/)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGjQrkxhOUTpwlBbGMZZC8UHx-rMc1ZvNhqT8V6CNk21HiLU007_PQi52wvIYb9ZbMlyiFrwoxRiPLywOT7FTeOSKc_E69pjEndasSQXdCxez5WdzVmI8TeKTMcpknbDJKcXhZbkFnXxw4s7o1tyGh30zA9eAumDO5Hb3DSY_gdTb4DarYGKPWSmVz7fRKqDO_HGgFSPYfFC1mtRcoZ79pB)
* [d2l.ai](https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGDv3a6Rk1HU5QmMMm9MZDS6cHj6l0sz8W68Cx4aAaBUX8l3EWpfJIltRQ3inzKCVr7ve5VRRzuXZOzChGq6QtcQMJG-poBHdCDuUdJFkPCElXdcVL3LJcsy-2FO2qKOMuY-JsSMosV9Hbl9kE77aN6nVzT5U08ogKNByHZZmhsLfRojXU5nMGvJjx0lHtdNI_yPk0FCv3WsyeMQsahmPj1ZvOAgN0UYTeanQwE)
* [quora.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFFi1YddBP10vPuywwgAmjCKefxJZiCYAeGZ1qMPwItmPFwEF1ExP-EFzaTSlEAR416I6d8AhjMGus3P5-8k2jQD70TbbmWWj2ji6OAJDA-gQeLR6k0patYgWuwx6NrxgI3jwq_J4eAjlqtl8yHeRhgfQeqUU3JPAKHO5-AZF6ITXnmP8pcAi3Wy5FzrS0Uu-DdkHSTTSqOkpXoCw==)
* [24-7pressrelease.com](https://www.24-7pressrelease.com/press-release/530181/from-phishing-to-bias-study-maps-the-hidden-threats-behind-large-language-models)
* [trek.ca](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEdgXVZdrVHD4cyW_svcFWEn8Fp0eyp5GD4bVfbDl_ZU1RSLsEBC3-25rMHz_e11klQuYwaibZeC0DJkLw1dJCO9JfsfsFQcx8DneJkpqg6yGxeHFd6NpRC81TfZveQ-LCQTxigt7EEv3iXhsSxO-csjjKMBiJnZa0-9JOADPsBHQsWhAFjtnj3QA7C)
* [forbes.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHeIAs7Uk8EZXPfeCFGO_DZwi7gL_VBRpNzaoOE-y1_Qcc6sasFysbWrKNQUcemZZF9UOKLDVv7T2oJovLvPjBZTDMAavTKVmIPe6vvUeaEva9XzkiqM2M6oc_0mCcTeJvq6wfRlMGNcEUy1yaCZ72CKh_iion7SaHEKca5rNBD2mwVBOSacHQcyhg2Gq6l59pLE7cVYrPu5NdDsUP7ED66q7a-pM71ZF0=)
* [byteplus.com](https://www.byteplus.com/en/topic/494147)
* [skywork.ai](https://skywork.ai/slide/en/automatic-summarization-ai-text-intelligence-2004131734178119680)
* [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHN72mqW4sQCiq4UmdxTnPpWk5xqMKHX03lkxzPObuSOw2nLIIOLPRrrb7Vf1HNwaQRwfq8ijPaTZUYVBH96v7YsAX4rSycnaRxQkr9_axtLm9d-Y-VzLpxJmgjst25NuNEuSFP0Z65XUsyJ9Hi9JYyawymZGnlHcTkOsD2N8f8Ekt5Wcw9m2BkQ0NKACqlYmXx8VbQ8Zm3bFtuG9un)
* [applify.com.sg](https://www.applify.com.sg/blog/natural-language-processing-in-artificial-intelligence)
* [issarice.com](https://timelines.issarice.com/wiki/Timeline_of_transformers)
* [dev.to](https://dev.to/amananandrai/recent-advances-in-the-field-of-nlp-33o1)


*ì´ ì½˜í…ì¸ ëŠ” AIì— ì˜í•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•í•œ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*