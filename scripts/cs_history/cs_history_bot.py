from google import genai
from google.genai import types
import os
import json
from datetime import datetime, timedelta
from json_repair import repair_json
import urllib.request
import traceback
import sys
import time

# Pydantic ëª¨ë¸ì´ ì •ì˜ëœ íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
# ë§Œì•½ íŒŒì¼ì´ ì—†ë‹¤ë©´ ì´ ë¶€ë¶„ì€ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
try:
    from cs_history_models import HistoryBotResponse, HistoryBotMetadata
except ImportError:
    # í˜¹ì‹œ ëª¨ë¥¼ ì‹¤í–‰ ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ë‚´ë¶€ ì •ì˜í•˜ê±°ë‚˜ ê²½ê³ ë¥¼ ë„ì›ë‹ˆë‹¤.
    print("âš ï¸ 'cs_history_models.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Pydantic ëª¨ë¸ ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    sys.exit(1)

# --- [Configuration] ---
# ë¹„ìš© íš¨ìœ¨ì„±ì„ ìœ„í•´ ì—­í• ì— ë”°ë¼ ëª¨ë¸ì„ ì´ì›í™”í•©ë‹ˆë‹¤.
RESEARCH_MODEL_NAME = "gemini-2.5-flash"  # ê²€ìƒ‰ ë° ì¡°ì‚¬ ë‹´ë‹¹ (ì†ë„ ë¹ ë¦„, ì €ë ´í•¨)
WRITER_MODEL_NAME = "gemini-3-flash-preview"      # ì‘ë¬¸ ë‹´ë‹¹ (ë¬¸ì¥ë ¥ ìš°ìˆ˜, ì¶”ë¡  ëŠ¥ë ¥ ë†’ìŒ)
STATE_FILE = "bot_state.json"

DEFAULT_STATE = {
    "day_count": 0,
    "last_run_date": "",
    "current_year": "N/A",
    "last_topic": "N/A",
    "next_topic": "ì°°ìŠ¤ ë°°ë¹„ì§€ì˜ í•´ì„ê¸°ê´€",
    "next_year": 1835
}

# --- [Prompt Definitions (English)] ---
# í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ì˜ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

def get_researcher_prompt():
    """Phase 1: í˜„ì¬ ì£¼ì œ ì‹¬ì¸µ íƒêµ¬ ì „ìš©"""
    return """
You are an 'AI Computer Science History Researcher'.
**Goal:** Research deep technical details about the specific event/figure provided.

**Instructions:**
1.  **Search Aggressively:** Find detailed specs, logic, and context.
2.  **Deep Dive:** Explain *how* it works and *why* it was a paradigm shift.
3.  **Modern Connections:** Trace the lineage to modern tech.
4.  **Output:** Structured summary for a blog post. Do NOT worry about the next topic.
"""

def get_planner_prompt():
    """Phase 1.5: ë‹¤ìŒ ì£¼ì œ ì„ ì • (Planner) ì „ìš©"""
    return """
You are the **'Chief Editor of Computer Science History'**.
Your job is to select the **single most important next milestone** in computer science history based on the provided current context.

**Selection Logic:**
* Identify the *single most important* next milestone in computer science history that happened *after* the current event.
    * **PRIORITIZE PARADIGM SHIFTS:** Do not simply choose the next incremental improvement in the same field. Look for technologies that changed how the *entire industry* works.
    * **EVALUATE IMPACT:** * Example: After 'AlexNet' (AI breakthrough), 'Docker' (2013, Infrastructure revolution) might be historically more significant than 'VGGNet' (AI improvement).

**Output Format:**
Return ONLY a JSON object:
{
    "next_topic": "Topic Name",
    "next_year": 20XX,
    "reasoning": "Why this was chosen over other candidates"
}
"""

def get_writer_prompt():
    """Phase 2: Pro/Flash ëª¨ë¸ì„ ìœ„í•œ ì§‘í•„ ì§€ì‹œë¬¸ (í˜ë¥´ì†Œë‚˜ ë³µêµ¬ ë²„ì „)"""
    return """
You are the **'AI Computer Science History Bot' (AI ì»´í“¨í„° ê³¼í•™ ì—­ì‚¬ ë´‡)**. 
Your mission is to introduce one important event or figure in computer science history every day.

**Identity & Tone:**
* **Persona:** Do NOT act as a human historian. You are a dedicated AI bot guiding users through the journey of computing history.
* **Tone:** Professional and insightful, but also friendly and enthusiastic.
* **Consistency:** Maintain a consistent voice with previous posts. You are helpful, objective, and deeply knowledgeable.

**Task:**
You will receive research notes from a researcher. Your task is to write a daily blog post in **fluent, engaging Korean**.

**Writing Guidelines:**
1.  **Greeting:** MUST start the "Engaging Opening Greeting" by introducing yourself as the "AI ì»´í“¨í„° ê³¼í•™ ì—­ì‚¬ ë´‡" and welcoming the reader to Day {day_count}.
2.  **Language:** Korean (Main text), but keep technical terms in English brackets where appropriate (e.g., í•´ì„ê¸°ê´€(Analytical Engine)).
3.  **Depth:** Even though you are a bot, your explanation must be technically deep (Deep Dive) and logically sound.

**Output Format:**
You MUST output a valid JSON object with the following structure. The 'content' field must be a Markdown string using the specific template below.

```json
{
    "content": "MARKDOWN_STRING",
    "metadata": {
        "current_year": int,
        "last_topic": "string",
        "next_topic": "string",
        "next_year": int
    }
}
```

**Markdown Template for 'content':**

Day {day_count}: {Title}

{Engaging Opening Greeting (As AI Bot)}

## ğŸ•°ï¸ ì˜¤ëŠ˜ì˜ í‚¤ì›Œë“œ: {Topic Name}
 * ì›ì–´: {Original Name}
 * ì‹œê¸°: {Year} ({Key Event})

{Main Body: Explanation of the figure/tech}

## âš¡ ë¬´ì—‡ì´ í˜ëª…ì ì´ì—ˆë‚˜? (Deep Dive)
{Technical deep dive explaining why this was a breakthrough, based on the research notes}

## ğŸ”— í˜„ëŒ€ì™€ì˜ ì—°ê²°: {Modern Analogy}
{Explain how this past concept connects to specific modern technologies (CPU, AI, etc.)}

## ğŸ“… ë‚´ì¼ì˜ í‚¤ì›Œë“œ ì˜ˆê³ 
{A hint about the next milestone mention in the metadata}
"""

# --- [Helper Functions] ---

def load_state():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    state_path = os.path.join(script_dir, STATE_FILE)
    if not os.path.exists(state_path):
        return DEFAULT_STATE
    with open(state_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_state(state):
    script_dir = os.path.dirname(os.path.abspath(__file__))
    state_path = os.path.join(script_dir, STATE_FILE)
    with open(state_path, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def get_final_url_urllib(initial_url):
    """ë¦¬ë‹¤ì´ë ‰íŠ¸ëœ ìµœì¢… URLì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        req = urllib.request.Request(initial_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req) as response:
            return response.geturl()
    except Exception:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì´ˆê¸° URL ë°˜í™˜
        return initial_url

# --- [Core Logic: Hybrid Pipeline] ---

def generate_daily_content(state):
    """
    í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸:
    1. Researcher (Flash): êµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ ì •ë³´ ìˆ˜ì§‘ ë° ì‚¬ì‹¤ í™•ì¸
    2. Writer (Pro): ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„±
    """
    client = genai.Client()
    
    # Context ë³€ìˆ˜ ì¤€ë¹„
    last_year = state['current_year']
    last_topic = state['last_topic']
    next_topic = state['next_topic']
    next_year = state['next_year']
    day_count = state['day_count']

    print(f"   ...Phase 1: Researching '{next_topic}' with {RESEARCH_MODEL_NAME}")

    # --- Phase 1: Research with Flash (Grounding Enabled) ---
    research_prompt = f"""
    Current Progress: Day {day_count-1}.
    Last Topic: '{last_topic}' ({last_year}).
    
    **TODAY'S MISSION:**
    Research the topic: '{next_topic}' which occurred around {next_year}.
    
    Find the facts, technical details, modern connections, and the NEXT historical milestone after this one.
    """
    
    grounding_tool = types.Tool(google_search=types.GoogleSearch())
    
    # Flash ëª¨ë¸ í˜¸ì¶œ
    research_config = types.GenerateContentConfig(
        system_instruction=get_researcher_prompt(),
        tools=[grounding_tool],
        temperature=0.0,  # ì‚¬ì‹¤ ìˆ˜ì§‘ì´ë¯€ë¡œ ì˜¨ë„ë¥¼ ë‚®ì¶¤
        thinking_config=types.ThinkingConfig(thinking_budget=24576, include_thoughts=False) # Dynamic thinking budget
    )

    research_response = None
    chunks = None
    
    # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§
    for attempt in range(3):
        try:
            research_response = client.models.generate_content(
                model=RESEARCH_MODEL_NAME,
                contents=research_prompt,
                config=research_config,
            )
            # ê²€ìƒ‰ ê²°ê³¼(Chunks)ê°€ ìˆëŠ”ì§€ í™•ì¸
            if research_response.candidates[0].grounding_metadata.grounding_chunks:
                chunks = research_response.candidates[0].grounding_metadata.grounding_chunks
                break
            else:
                print(f"      (Attempt {attempt+1}: No grounding chunks found. Retrying...)")
                time.sleep(2) # ì§§ì€ ëŒ€ê¸°
        except Exception as e:
            print(f"      (Attempt {attempt+1} Failed: {e})")
            time.sleep(2 * (attempt + 1))
            if attempt == 2: raise

    # Phase 1 ê²°ê³¼ì—ì„œ ì¸ìš©êµ¬ ì²˜ë¦¬
    citation_list_str = ""
    if chunks:
        for x in chunks:
            try:
                # ìµœì¢… URL í™•ì¸ (ì„ íƒ ì‚¬í•­, ì†ë„ê°€ ëŠë¦¬ë‹¤ë©´ ì œê±° ê°€ëŠ¥)
                final_url = get_final_url_urllib(x.web.uri)
                title = x.web.title if x.web.title else "Reference"
                citation_list_str += f"* [{title}]({final_url})\n"
            except:
                continue
    else:
        citation_list_str = "* (No web citations found during research phase)\n"

    research_notes = research_response.text

    print(f"      Collected {len(chunks)} chunks")

    print(f"   ...Phase 1.5: Selecting NEXT topic...")
    
    # ìµœê·¼ ê¸°ë¡ ë¬¸ìì—´ ìƒì„± (state ê´€ë¦¬ í•„ìš”, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”)
    recent_history_str = f"Previous: {state.get('last_topic', 'N/A')}, Current: {next_topic}"

    planner_config = types.GenerateContentConfig(
        system_instruction=get_planner_prompt(),
        tools=[grounding_tool],
        temperature=0.0,  # ì‚¬ì‹¤ ìˆ˜ì§‘ì´ë¯€ë¡œ ì˜¨ë„ë¥¼ ë‚®ì¶¤
        thinking_config=types.ThinkingConfig(thinking_budget=24576, include_thoughts=False) # Dynamic thinking budget
    )

    planner_prompt = f"""
**Current Context:**
* Current Topic: {next_topic} ({next_year})
* Recent Topics History: {recent_history_str} (Consider this to avoid excessive repetition unless necessary)
"""

    # Plannerë„ Flash ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥´ê³  ì €ë ´í•¨)
    planner_response = client.models.generate_content(
        model=RESEARCH_MODEL_NAME, # gemini-2.5-flash
        contents=planner_prompt,
        config=planner_config
    )

    print(f"      Planner Response: {planner_response.text}")

    next_plan = json.loads(repair_json(planner_response.text))
    print(f"      -> Next Plan: {next_plan['next_topic']} ({next_plan['next_year']})")
    print(f"      -> Reason: {next_plan['reasoning']}")


    print(f"   ...Phase 2: Writing content with {WRITER_MODEL_NAME}")

    # --- Phase 2: Writing with Pro (No Grounding Tool) ---
    # [ìˆ˜ì •] Writerì—ê²ŒëŠ” ë” ì´ìƒ ì¸ìš©êµ¬ ëª©ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì£¼ì§€ ì•Šìœ¼ë©°, 
    # ë³¸ë¬¸ ì‘ì„±ì—ë§Œ ì§‘ì¤‘í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤.
    writer_user_prompt = f"""
    **Task:** Write the blog post for Day {day_count}.
    
    **Research Data:**
    {research_notes}

    **Planning Data (For Metadata):**
    Next Topic: {next_plan['next_topic']}
    Next Year: {next_plan['next_year']}

    **Context:**
    Last Topic: {last_topic} ({last_year})
    Today's Topic: {next_topic} ({next_year})
    """

    writer_config = types.GenerateContentConfig(
        system_instruction=get_writer_prompt(),
        temperature=0.4, # ì°½ì˜ì ì¸ ê¸€ì“°ê¸°ë¥¼ ìœ„í•´ ì˜¨ë„ ìƒí–¥
        #response_mime_type='application/json',
        #response_json_schema=HistoryBotResponse.model_json_schema(),
        thinking_config=types.ThinkingConfig(thinking_level="high", include_thoughts=False) # Dynamic thinking budget
    )

    writer_response = client.models.generate_content(
        model=WRITER_MODEL_NAME,
        contents=writer_user_prompt,
        config=writer_config
    )

    # JSON íŒŒì‹± ë° ë³µêµ¬
    response_json = HistoryBotResponse.model_validate_json(repair_json(writer_response.text))

    # [ì¤‘ìš”] íŒŒì´ì¬ ì½”ë“œ ë ˆë²¨ì—ì„œì˜ í›„ì²˜ë¦¬ (Post-processing)
    # AIì˜ í™˜ê°(Hallucination) ë°©ì§€ë¥¼ ìœ„í•´ ì°¸ê³  ë¬¸í—Œê³¼ ë©´ì±… ì¡°í•­ì€ ì§ì ‘ ë¬¸ìì—´ ê²°í•©
    response_json.content += f"\n\n## ğŸ“š ì°¸ê³  ë¬¸í—Œ\n{citation_list_str}"
    response_json.content += f"\n\n*ì´ ì½˜í…ì¸ ëŠ” AIì— ì˜í•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•í•œ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*"
    
    return response_json

# --- [Main Execution] ---

def extract_metadata(content, current_state):    
    new_state = current_state.copy()
    new_state['day_count'] += 1
    new_state['last_run_date'] = datetime.now().strftime("%Y-%m-%d")
    new_state['current_year'] = content.metadata.current_year
    new_state['last_topic'] = content.metadata.last_topic
    new_state['next_topic'] = content.metadata.next_topic
    new_state['next_year'] = content.metadata.next_year
    return new_state

def main():
    state = load_state()
    
    current_actual_year = datetime.now().year
    termination_threshold = current_actual_year - 3

    # ì¢…ë£Œ ì¡°ê±´ ê²€ì‚¬
    next_year_candidate = state.get('next_year')
    if not isinstance(next_year_candidate, int) or next_year_candidate >= termination_threshold:
        if state['day_count'] > 0:
            print("ğŸ›‘ [ì•Œë¦¼] ì—­ì‚¬ ë´‡ì˜ ì—¬ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
             print("âš ï¸ [ê²½ê³ ] ì´ˆê¸° ìƒíƒœ ì˜¤ë¥˜. bot_state.jsonì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ğŸ¤– Day {state['day_count']} ì½˜í…ì¸  ìƒì„± ì‹œì‘... ({state['next_year']}ë…„ {state['next_topic']})")
    
    try:
        # í•˜ì´ë¸Œë¦¬ë“œ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
        content_response = generate_daily_content(state)
        
        # --- ì¢…ë£Œ ì¡°ê±´ ë„ë‹¬ ì‹œ 'ë‚´ì¼ì˜ ì˜ˆê³ ' êµì²´ ë¡œì§ (ê¸°ì¡´ ìœ ì§€) ---
        if content_response.metadata.next_year >= termination_threshold:
            target_header = "## ğŸ“… ë‚´ì¼ì˜ í‚¤ì›Œë“œ ì˜ˆê³ "
            citation_header = "## ğŸ“š ì°¸ê³  ë¬¸í—Œ"
            
            replacement_section = f"""
## ğŸ›‘ ê¸´ ì—¬ì •ì˜ ë§ˆì¹¨í‘œ
ìš°ë¦¬ëŠ” ì°°ìŠ¤ ë°°ë¹„ì§€ì˜ í•´ì„ê¸°ê´€ë¶€í„° ì‹œì‘í•´ ìˆ¨ ê°€ì˜ê²Œ ë‹¬ë ¤ì™”ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì´ì •í‘œëŠ” {content_response.metadata.next_year}ë…„ì˜ '{content_response.metadata.next_topic}'ì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ ë³¸ ì—­ì‚¬ ë´‡ì€ ë™ì‹œëŒ€ì˜ ì‚¬ê±´ì— ëŒ€í•œ í‰ê°€ëŠ” ë¯¸ë˜ì˜ ì—­ì‚¬ê°€ë“¤ì—ê²Œ ë§¡ê¸°ê³ , 
í˜„ì¬ë¡œë¶€í„° 3ë…„ ì „ê¹Œì§€ì˜ ê¸°ë¡ì„ ëìœ¼ë¡œ ê¸´ ì—¬ì •ì„ ë§ˆë¬´ë¦¬í•˜ê³ ì í•©ë‹ˆë‹¤.

ì˜¤ëŠ˜ì´ ë°”ë¡œ ê·¸ ë§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤.
ê·¸ë™ì•ˆ 'ìƒê°í•˜ëŠ” ê¸°ê³„'ë¥¼ í–¥í•œ ì¸ë¥˜ì˜ ìœ„ëŒ€í•œ ì—¬ì •ì— í•¨ê»˜ í•´ì£¼ì…”ì„œ ì§„ì‹¬ìœ¼ë¡œ ê°ì‚¬í•©ë‹ˆë‹¤.
"""
            # ì•ˆì „í•˜ê²Œ ë³¸ë¬¸ êµì²´
            if target_header in content_response.content:
                base_content = content_response.content.split(target_header)[0].strip()
                citation_start_index = content_response.content.find(citation_header)
                if citation_start_index != -1:
                    footer_content = content_response.content[citation_start_index:]
                else:
                    footer_content = ""
                content_response.content = f"{base_content}\n\n{replacement_section}\n\n{footer_content}"

        # íŒŒì¼ ì €ì¥ ë¡œì§
        content = content_response.content.strip()
        # ì œëª© ì¶”ì¶œ (ì²« ì¤„) ë° ë§ˆí¬ë‹¤ìš´(#) ì œê±°
        title = content.splitlines()[0].replace("#", "").strip()
        
        body = "\n".join(content.splitlines()[1:]).strip()
        filename = f"{datetime.now().strftime('%Y-%m-%d')}-day{state['day_count']}.md"
        
        # Jekyll/Github Pages í˜¸í™˜ìš© Front matter
        header = f"""
---
title:  "{title}"
categories:
  - cs_history
toc: true
toc_sticky: true
comments: true
---
"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # ì €ì¥ ê²½ë¡œ ì„¤ì • (ìƒìœ„ í´ë”ì˜ _posts/cs_history)
        target_dir = os.path.normpath(os.path.join(script_dir, "..", "..", "_posts", "cs_history"))
        os.makedirs(target_dir, exist_ok=True)
        
        with open(os.path.join(target_dir, filename), 'w', encoding='utf-8') as f:
            f.write(header.strip() + "\n\n" + body)

        new_state = extract_metadata(content_response, state)
        save_state(new_state)
        print("ğŸ’¾ ìƒíƒœ ì €ì¥ ë° íŒŒì¼ ìƒì„± ì™„ë£Œ.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        raise

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        sys.exit(1)