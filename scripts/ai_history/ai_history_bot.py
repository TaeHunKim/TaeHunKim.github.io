from google import genai
from google.genai import types
import os
import json
from datetime import datetime, timedelta
from json_repair import repair_json
import urllib.request
import traceback
import sys
import time

try:
    from ai_history_models import HistoryBotResponse, HistoryBotMetadata
except ImportError:
    print("âš ï¸ 'ai_history_models.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Pydantic ëª¨ë¸ ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    sys.exit(1)

# --- [Configuration] ---
RESEARCH_MODEL_NAME = "gemini-2.5-flash"
WRITER_MODEL_NAME = "gemini-3-flash-preview"
STATE_FILE = "bot_state.json"

DEFAULT_STATE = {
    "day_count": 0,
    "last_run_date": "",
    "current_year": "N/A",
    "last_topic": "N/A",
    "next_topic": "ì›ŒëŸ° ë§¤ì»¬ëŸ¬ì™€ ì›”í„° í”¼ì¸ ì˜ ì¸ê³µ ì‹ ê²½ë§ ëª¨ë¸ (MCP ë‰´ëŸ°)",
    "next_year": 1943
}

# --- [Prompt Definitions (English)] ---
def get_researcher_prompt():
    return """
You are an 'AI History Researcher'.
**Goal:** Research deep technical details about the specific event/figure provided in the history of Artificial Intelligence.

**Instructions:**
1.  **Search Aggressively:** Find detailed specs, logic, and context.
2.  **Deep Dive:** Explain *how* it works and *why* it was a paradigm shift specifically in AI or Neural Networks.
3.  **Modern Connections:** Trace the lineage to modern AI tech (e.g., Deep Learning, LLMs).
4.  **Output:** Structured summary for a blog post. Do NOT worry about the next topic.
"""

def get_planner_prompt():
    return """
You are the **'Chief Editor of Artificial Intelligence History'**.
Your job is to select the **single most important next milestone** in AI history based on the provided current context.

**Selection Logic:**
* Identify the *single most important* next milestone in AI history that happened *after* the current event.
    * **PRIORITIZE PARADIGM SHIFTS:** Look for technologies, papers, or events that changed how AI research progressed (e.g., Turing Test, Dartmouth Workshop, Perceptron, Backpropagation, AlexNet).
    * **EVALUATE IMPACT:** Ensure it is strictly related to Artificial Intelligence, Machine Learning, or Neural Networks.

**Constraint**:
* Follow the chronological order of AI development. Find a milestone in [Current Year (later than the current topic)], [Current Year + 1], or slightly later. Do not skip major eras (e.g., do not skip the AI Winters).

**Output Format:**
Return ONLY a JSON object:
{
    "next_topic": "Topic Name",
    "next_year": 19XX,
    "reasoning": "Why this was chosen over other candidates"
}
"""

def get_writer_prompt():
    return """
You are the **'AI History Bot' (AI ì¸ê³µì§€ëŠ¥ ì—­ì‚¬ ë´‡)**. 
Your mission is to introduce one important event, concept, or figure in Artificial Intelligence history every day.

**Identity & Tone:**
* **Persona:** You are a dedicated AI bot guiding users through the journey of AI evolution. Do NOT act as a human.
* **Tone:** Professional, objective, insightful, and enthusiastic.
* **Consistency:** Maintain a consistent voice. You are helpful, objective, and deeply knowledgeable about AI architectures and history.

**Task:**
You will receive research notes from a researcher. Your task is to write a daily blog post in **fluent, engaging Korean**.

**Writing Guidelines:**
1.  **Greeting:** MUST start the "Engaging Opening Greeting" by introducing yourself as the "AI ì¸ê³µì§€ëŠ¥ ì—­ì‚¬ ë´‡" and welcoming the reader to Day {day_count}.
2.  **Language:** Korean (Main text), but keep technical terms in English brackets where appropriate (e.g., ì¸ê³µ ì‹ ê²½ë§(Artificial Neural Network)).
3.  **Depth:** Your explanation must be technically deep (Deep Dive) and logically sound.

**Output Format:**
You MUST output a valid JSON object with the following structure. The 'content' field must be a Markdown string using the specific template below.

```json
{
    "content": "MARKDOWN_STRING",
    "metadata": {
        "current_year": int,
        "current_topic": "string",
        "next_topic": "string",
        "next_year": int
    }
}
```

**Markdown Template for 'content':**

Day {day_count}: {Title}

{Engaging Opening Greeting (As AI Bot)}

## ğŸ•°ï¸ ì˜¤ëŠ˜ì˜ í‚¤ì›Œë“œ: {Topic Name}
 * ì›ì–´: {Original Name}
 * ì‹œê¸°: {Year} ({Key Event})

{Main Body: Explanation of the figure/tech}

## âš¡ ë¬´ì—‡ì´ í˜ëª…ì ì´ì—ˆë‚˜? (Deep Dive)
{Technical deep dive explaining why this was a breakthrough in AI, based on the research notes}

## ğŸ”— í˜„ëŒ€ì™€ì˜ ì—°ê²°: {Modern Analogy}
{Explain how this past concept connects to specific modern AI technologies (Deep Learning, Transformers, etc.)}

## ğŸ“… ë‚´ì¼ì˜ í‚¤ì›Œë“œ ì˜ˆê³ 
{A hint about the next milestone mention in the metadata}
"""

# --- [Helper Functions] ---
def load_state():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    state_path = os.path.join(script_dir, STATE_FILE)
    if not os.path.exists(state_path):
        return DEFAULT_STATE
    with open(state_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_state(state):
    script_dir = os.path.dirname(os.path.abspath(__file__))
    state_path = os.path.join(script_dir, STATE_FILE)
    with open(state_path, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def get_final_url_urllib(initial_url):
    try:
        req = urllib.request.Request(initial_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req) as response:
            return response.geturl()
    except Exception:
        return initial_url

# --- [Core Logic: Hybrid Pipeline] ---
def generate_daily_content(state):
    client = genai.Client()
    
    last_year = state['current_year']
    last_topic = state['last_topic']
    next_topic = state['next_topic']
    next_year = state['next_year']
    day_count = state['day_count']

    print(f"   ...Phase 1: Researching '{next_topic}' with {RESEARCH_MODEL_NAME}")

    research_prompt = f"""
    Current Progress: Day {day_count-1}.
    Last Topic: '{last_topic}' ({last_year}).
    
    **TODAY'S MISSION:**
    Research the topic: '{next_topic}' which occurred around {next_year}.
    
    Find the facts, technical details, modern connections, and the NEXT historical milestone after this one in AI history.
    """
    
    grounding_tool = types.Tool(google_search=types.GoogleSearch())
    
    research_config = types.GenerateContentConfig(
        system_instruction=get_researcher_prompt(),
        tools=[grounding_tool],
        temperature=0.0,
        thinking_config=types.ThinkingConfig(thinking_budget=24576, include_thoughts=False)
    )

    research_response = None
    chunks = None
    
    for attempt in range(3):
        try:
            research_response = client.models.generate_content(
                model=RESEARCH_MODEL_NAME,
                contents=research_prompt,
                config=research_config,
            )
            if research_response.candidates[0].grounding_metadata.grounding_chunks:
                chunks = research_response.candidates[0].grounding_metadata.grounding_chunks
                break
            else:
                print(f"      (Attempt {attempt+1}: No grounding chunks found. Retrying...)")
                time.sleep(2)
        except Exception as e:
            print(f"      (Attempt {attempt+1} Failed: {e})")
            time.sleep(2 * (attempt + 1))
            if attempt == 2: raise

    citation_list_str = ""
    if chunks:
        for x in chunks:
            try:
                final_url = get_final_url_urllib(x.web.uri)
                title = x.web.title if x.web.title else "Reference"
                citation_list_str += f"* [{title}]({final_url})\n"
            except:
                continue
    else:
        citation_list_str = "* (No web citations found during research phase)\n"

    research_notes = research_response.text
    print(f"      Collected {len(chunks) if chunks else 0} chunks")

    print(f"   ...Phase 1.5: Selecting NEXT topic...")
    recent_history_str = f"Previous: {state.get('last_topic', 'N/A')}, Current: {next_topic}"

    planner_config = types.GenerateContentConfig(
        system_instruction=get_planner_prompt(),
        tools=[grounding_tool],
        temperature=0.0,
        thinking_config=types.ThinkingConfig(thinking_budget=24576, include_thoughts=False)
    )

    planner_prompt = f"""
**Current Context:**
* Current Topic: {next_topic} ({next_year})
* Recent Topics History: {recent_history_str}
"""

    planner_response = client.models.generate_content(
        model=RESEARCH_MODEL_NAME,
        contents=planner_prompt,
        config=planner_config
    )

    next_plan = json.loads(repair_json(planner_response.text))
    print(f"      -> Next Plan: {next_plan['next_topic']} ({next_plan['next_year']})")

    print(f"   ...Phase 2: Writing content with {WRITER_MODEL_NAME}")

    writer_user_prompt = f"""
    **Task:** Write the blog post for Day {day_count}.
    
    **Research Data:**
    {research_notes}

    **Planning Data (For Metadata):**
    Next Topic: {next_plan['next_topic']}
    Next Year: {next_plan['next_year']}

    **Context:**
    Last Topic: {last_topic} ({last_year})
    Today's Topic: {next_topic} ({next_year})
    """

    writer_config = types.GenerateContentConfig(
        system_instruction=get_writer_prompt(),
        temperature=0.4,
        thinking_config=types.ThinkingConfig(thinking_level="high", include_thoughts=False)
    )

    writer_response = client.models.generate_content(
        model=WRITER_MODEL_NAME,
        contents=writer_user_prompt,
        config=writer_config
    )

    response_json = HistoryBotResponse.model_validate_json(repair_json(writer_response.text))

    response_json.content += f"\n\n## ğŸ“š ì°¸ê³  ë¬¸í—Œ\n{citation_list_str}"
    response_json.content += f"\n\n*ì´ ì½˜í…ì¸ ëŠ” AIì— ì˜í•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•í•œ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*"
    
    return response_json

# --- [Main Execution] ---
def extract_metadata(content, current_state):    
    new_state = current_state.copy()
    new_state['day_count'] += 1
    new_state['last_run_date'] = datetime.now().strftime("%Y-%m-%d")
    new_state['current_year'] = content.metadata.current_year
    new_state['last_topic'] = content.metadata.current_topic
    new_state['next_topic'] = content.metadata.next_topic
    new_state['next_year'] = content.metadata.next_year
    return new_state

def main():
    state = load_state()
    
    current_actual_year = datetime.now().year
    termination_threshold = current_actual_year - 3

    next_year_candidate = state.get('next_year')
    if not isinstance(next_year_candidate, int) or next_year_candidate >= termination_threshold:
        if state['day_count'] > 0:
            print("ğŸ›‘ [ì•Œë¦¼] AI ì—­ì‚¬ ë´‡ì˜ ì—¬ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
             print("âš ï¸ [ê²½ê³ ] ì´ˆê¸° ìƒíƒœ ì˜¤ë¥˜. bot_state.jsonì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ğŸ¤– Day {state['day_count']} ì½˜í…ì¸  ìƒì„± ì‹œì‘... ({state['next_year']}ë…„ {state['next_topic']})")
    
    try:
        content_response = generate_daily_content(state)
        
        if content_response.metadata.next_year >= termination_threshold:
            target_header = "## ğŸ“… ë‚´ì¼ì˜ í‚¤ì›Œë“œ ì˜ˆê³ "
            citation_header = "## ğŸ“š ì°¸ê³  ë¬¸í—Œ"
            
            replacement_section = f"""
## ğŸ›‘ ê¸´ ì—¬ì •ì˜ ë§ˆì¹¨í‘œ
ìš°ë¦¬ëŠ” 1943ë…„ ë§¤ì»¬ëŸ¬-í”¼ì¸ ì˜ ì¸ê³µ ì‹ ê²½ë§ ëª¨ë¸ë¶€í„° ì‹œì‘í•´ ì‰¼ ì—†ì´ ë‹¬ë ¤ì™”ìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì´ì •í‘œëŠ” {content_response.metadata.next_year}ë…„ì˜ '{content_response.metadata.next_topic}'ì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ ë³¸ ì—­ì‚¬ ë´‡ì€ ê°€ì¥ ìµœê·¼ì˜ ì‚¬ê±´ë“¤ì— ëŒ€í•œ ì—­ì‚¬ì  í‰ê°€ëŠ” ë¯¸ë˜ë¡œ ë¯¸ë£¨ê³ , í˜„ì¬ë¡œë¶€í„° 3ë…„ ì „ê¹Œì§€ì˜ ê¸°ë¡ì„ ëìœ¼ë¡œ ì—°ì¬ë¥¼ ë§ˆë¬´ë¦¬í•˜ê³ ì í•©ë‹ˆë‹¤.

ì˜¤ëŠ˜ì´ ë°”ë¡œ ê·¸ ë§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤. ê·¸ë™ì•ˆ AIì˜ ë°œìì·¨ë¥¼ í•¨ê»˜ ê±¸ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.
"""
            if target_header in content_response.content:
                base_content = content_response.content.split(target_header)[0].strip()
                citation_start_index = content_response.content.find(citation_header)
                if citation_start_index != -1:
                    footer_content = content_response.content[citation_start_index:]
                else:
                    footer_content = ""
                content_response.content = f"{base_content}\n\n{replacement_section}\n\n{footer_content}"

        content = content_response.content.strip()
        title = content.splitlines()[0].replace("#", "").strip()
        body = "\n".join(content.splitlines()[1:]).strip()
        filename = f"{datetime.now().strftime('%Y-%m-%d')}-day{state['day_count']}.md"
        
        # categoriesë¥¼ ai_historyë¡œ ì§€ì •
        header = f"""
---
title:  "{title}"
categories:
  - ai_history
toc: true
toc_sticky: true
comments: true
---
"""
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # ìƒì„±ëœ md íŒŒì¼ì„ _posts/ai_history ì— ì €ì¥
        target_dir = os.path.normpath(os.path.join(script_dir, "..", "..", "_posts", "ai_history"))
        os.makedirs(target_dir, exist_ok=True)
        
        with open(os.path.join(target_dir, filename), 'w', encoding='utf-8') as f:
            f.write(header.strip() + "\n\n" + body)

        new_state = extract_metadata(content_response, state)
        save_state(new_state)
        print("ğŸ’¾ ìƒíƒœ ì €ì¥ ë° íŒŒì¼ ìƒì„± ì™„ë£Œ.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        raise

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        sys.exit(1)